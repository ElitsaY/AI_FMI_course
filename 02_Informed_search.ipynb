{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5070606",
   "metadata": {},
   "source": [
    "# Lab02: Informed search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce290cdf",
   "metadata": {},
   "source": [
    "Overvirew of the lab: \n",
    "1. Recap from lab 01\n",
    "2. Heuristics\n",
    "3. Greedy\n",
    "4. Beam search \n",
    "5. Hill climbing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef0959",
   "metadata": {},
   "source": [
    "Recap from lab 01: \n",
    "Strategies are evaluated along the following dimensions:\n",
    "  * **Completeness:** does it always find solution if one exists?\n",
    "  * **Optimality**: does it always find a least-cost solution?\n",
    "  * **Time complexity**: bumber of nodes generated/expanded. We are interested in the worst case scenario\n",
    "  * **Space Complexity**: maximum number of nodes in memory\n",
    "\n",
    "Time and space complexity are measured in terms of:\n",
    "* **b** ‚Äì maximum branching factor of the search tree\n",
    "* **d** ‚Äì depth of the least-cost solution\n",
    "* **m** ‚Äì maximum depth of the state space (may be ‚àû)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb1a59",
   "metadata": {},
   "source": [
    "**Uninformed Search:** Uninformed strategies use only the information available in the problem definition.\n",
    "\n",
    "**Informed Search:** Informed strategies have information on the goal state which helps in more efficient searching. This information is obtained by a function (heuristic) that estimates how close a state is to the goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7995de6",
   "metadata": {},
   "source": [
    "Informed Search algorithms: \n",
    "- **Greedy** \n",
    "  - Beam Search \n",
    "  - Hill Climbing\n",
    "- **A*** \n",
    "  - Memory-Bounded A* \n",
    "  - iterative Deepening A* (IDA*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740e601",
   "metadata": {},
   "source": [
    "## Heuristic\n",
    "Heuristics are the driving force that allow estimation of distance to goal states - they‚Äôre functions that take in a state as input and output a corresponding estimate. The computation performed by such a function is specific to the search problem being solved.\n",
    "\n",
    "With heuristics, it becomes very easy to implement logic in our agent that enables them to ‚Äúprefer‚Äù expanding states that are estimated to be closer to goal states when deciding which action to perform. \n",
    "\n",
    "A function $h(n)$ that estimates the cost (or distance) from a given state n to a goal state. It provides problem-specific guidance to search algorithms to prefer more promising states and reduce the search effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbca7a",
   "metadata": {},
   "source": [
    "## Greedy\n",
    "\n",
    "**Description**: Greedy search is a strategy for exploration that always selects the frontier node with the lowest heuristic value for expansion, which corresponds to the state it believes is nearest to a goal.\n",
    "\n",
    "**Frontier representation**:  Greedy search operates identically to UCS, with a priority queue \n",
    "\n",
    "Greedy search is not guaranteed to find a goal state if one exists, nor is it optimal, particularly in cases where a very bad heuristic function is selected. It generally acts fairly unpredictably from scenario to scenario, and can range from going straight to a goal state to acting like a badly-guided DFS and exploring all the wrong areas.\n",
    "\n",
    "-----\n",
    "- **Complete**: No, but Complete in finite space with repeated-state checking\n",
    "-----\n",
    "- **Optimal** : No \n",
    "-----\n",
    "- **Time complexity** : $O(b^m)$ - a misleading \"bad\" heuristic may lead us to possibly explore all nodes\n",
    "-----\n",
    "- **Space complexity** : $O(b^m)$ - keep all nodes in memeory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55349588",
   "metadata": {},
   "source": [
    "## Beam search (Local Beam Search)\n",
    "= greedy best-first search with queue limit $l$, i.e., keeps $l$ nodes in the queue\n",
    "\n",
    "-----\n",
    "- **Complete**: No, local search\n",
    "-----\n",
    "- **Optimal** : No \n",
    "-----\n",
    "- **Time complexity** : $O(bml)$ \n",
    "\n",
    "**Expansion:** The algorithm only expands the $l$ nodes selected from the previous level.\n",
    "\n",
    "**Generation of Successors:** Each of the $l$ nodes generates $b$ successors (children).The total number of new candidates generated at this level is $l \\times b$.\n",
    "\n",
    "**Heuristic Evaluation/Scoring:** The algorithm calculates the score for all $l \\cdot b$ candidates.This step takes time proportional to $\\mathcal{O}(B \\cdot b)$.\n",
    "\n",
    "**Pruning (Selection):** The algorithm selects the best $B$ candidates out of the $B \\cdot b$ total to carry forward to the next level.Sorting or selection takes time, often $\\mathcal{O}(l \\cdot b \\log(l \\cdot b))$ if sorting is done, or faster if efficient selection algorithms (like Quickselect or a min-heap) are used. In many common search contexts, *this selection step is often simplified or amortized, or assumed to be minor compared to the expansion cost, leading to the linear complexity*.\n",
    "\n",
    "**Overall Time Complexity**: Since the process is repeated for $m$ levels, the total time complexity is: ${O}(m \\cdot l \\cdot b)$\n",
    " \n",
    "----\n",
    "- **Space complexity** : $O(bl)$ - linear space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37bd04",
   "metadata": {},
   "source": [
    "## Hill Climbing\n",
    "= greedy best-first search with queue limit l = 1, i.e., keeps only the best node\n",
    "\n",
    "-----\n",
    "- **Complete**: No\n",
    "----\n",
    "- **Optimal** : No \n",
    "-----\n",
    "- **Time complexity** : $O(bm)$ \n",
    "----\n",
    "\n",
    "- **Space Complexity** : $O(b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a931763",
   "metadata": {},
   "source": [
    "## Hill Climbing and Beam Search\n",
    "Key use case: optimization problems\n",
    "* Beam Search and Hill Climbing are better suited for optimization rather than pathfinding.\n",
    "\n",
    "* In optimization, the focus is on iteratively improving asolution, rather than searching for a direct path between A and B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13857e1b",
   "metadata": {},
   "source": [
    "Applications of Beam Search in AI üîé\n",
    "- Natural Language Processing (NLP):\n",
    "  - Machine Translation: Translating a sentence from a source language to a target language by selecting the sequence of words with the highest probability.\n",
    "  - Text Summarization: Generating a coherent and concise summary by selecting the most probable sequence of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ea038",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
