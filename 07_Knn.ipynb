{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42978438",
   "metadata": {},
   "source": [
    "# Lab 07: KNN\n",
    "\n",
    "Overview of the lab:\n",
    "* Global Learning vs Local Learning\n",
    "* Instance-Based Learning vs Model-Based Learning\n",
    "* Lazy Learning vs Eager Learning\n",
    "* KNN\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3e0e1",
   "metadata": {},
   "source": [
    "## Global Learning vs Local Learning \n",
    "* Global Learning: Learning from all instances in the dataset.\n",
    "    * Linear Regression\n",
    "    * Naïve Bayes Classifier\n",
    "* Local Learning: Learning from some of the instances in the dataset.\n",
    "    * kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76315b0",
   "metadata": {},
   "source": [
    "##  Instance-Based Learning vs Model-Based Learning\n",
    "* Instance-Based Learning: Use the entire dataset as the model.\n",
    "    * kNN\n",
    "* Model-Based Learning: Use the training data to create a model that has parameters learned from the training data.\n",
    "    * Linear Regression\n",
    "    * Naïve Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fca28",
   "metadata": {},
   "source": [
    "## Lazy Learning vs Eager Learning\n",
    "* Lazy learning (e.g., instance-based learning): Simply stores\n",
    "training data (or only minor processing) and waits until it is\n",
    "given a test tuple\n",
    "* Eager learning (eg. Decision trees, SVM, NN): Given a set of\n",
    "training set, constructs a classification model before receiving\n",
    "new (e.g., test) data to classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef8040",
   "metadata": {},
   "source": [
    "## KNN: Kth nearest neightbours \n",
    "\n",
    "### Advantages\n",
    "\n",
    "* Simplicity and Intuition: KNN is very easy to understand and implement. The core concept—that similar points are close to each other—is highly intuitive.\n",
    "\n",
    "* No Training Phase (Lazy Learner): Since it's a lazy learning algorithm, KNN simply stores the entire training dataset. There is no complex training or model-building process upfront, which can make it very fast to \"train.\"\n",
    "\n",
    "* Adaptable to New Data: The model is not fixed after a training period. New data can be added seamlessly without requiring a full retraining process.\n",
    "\n",
    "* Non-Parametric: KNN makes no underlying assumptions about the data's distribution (e.g., that the data is linear or normally distributed). This makes it effective for data where decision boundaries are non-linear or complex.\n",
    "\n",
    "* Versatility: It can be used effectively for both classification (majority vote) and regression (averaging neighbor values) tasks.\n",
    "\n",
    "\n",
    "### Disadvantages"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
