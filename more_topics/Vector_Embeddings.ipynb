{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011b81df",
   "metadata": {},
   "source": [
    "# Vector embeddings\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "1. Words as numbers\n",
    "2. Map of meaning\n",
    "3. Embedding arithmetic\n",
    "4. Cosine similarity\n",
    "5. Vector Databases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8484735",
   "metadata": {},
   "source": [
    "## 1. Words as numbers\n",
    "* Representing discrete entities like words as numerical vector in high-dimentional space\n",
    "\n",
    "## 2. Map of meaning\n",
    "* **Embedding space:** the geometric space where vectors reside. Distances and angles correspond to semantic relationships\n",
    "\n",
    "## 3. Embedding arithmetic \n",
    "* Expoits the algebraic properties of vector spaces to model analogical reasoning. \n",
    "\n",
    "## 4. Cosine similarity \n",
    "* Quantifies the angular distancr brtween 2 embeddings to meausre their semantix proximity\n",
    "\n",
    "## 5. Vector databases \n",
    "* The infrastructure backbone for semantic retrieval. They store and query embeddings efficiently."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
