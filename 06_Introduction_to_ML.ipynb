{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf45778b",
   "metadata": {},
   "source": [
    "# Lab06: Introduction to Machine Learning\n",
    "\n",
    "Overview of the lab:\n",
    "1. Machine Learning Concepts \n",
    "2. Classical Machine Learning \n",
    "3. Supervised Machine Learning \n",
    "4. Unsupervised Machine Learning\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa49b2f",
   "metadata": {},
   "source": [
    "## 1. Machiine Learning Concepts\n",
    "\n",
    "### 1.1 The Foundation: AI and Machine Learning \n",
    "* **Artificial Intelligence (AI):** The capability of machines to perform tasks requiring human intelligence, such as understanding language, recognizing images, and making decisions. Not all AI is machine learning (e.g., rule-based systems or typical chess engines).\n",
    "\n",
    "* **Machine Learning (ML):** A branch of AI that enables computers to learn from data and improve performance over time without explicit programming. It identifies patterns to make predictions or decisions on new, unseen information (e.g., a spam filter).\n",
    "\n",
    "### 1.2 Core Data and Model Concepts \n",
    "* **Data:** Information collected, analyzed, and used to make decisions. In ML, this can be numbers, text, images (pixel intensities), or any form of input.\n",
    "\n",
    "* **Model**: A mathematical representation trained to recognize patterns in data and make predictions. It's often a mapping function between an input and an output( e.g the line equation in linear regression).\n",
    "\n",
    "* **Model Fitting / Training / Learning**: The process of adjusting a model's internal parameters to find the best match between its predictions and the actual data.\n",
    "\n",
    "* **Training Data:** A subset of data used to teach the model, consisting of input examples paired with their correct outputs (labels).\n",
    "\n",
    "* **Test Data (Test Set)**: A completely separate collection of data used only to evaluate how well the trained model performs on examples it hasn't seen.\n",
    "\n",
    "### 1.3 Machine Learning Learning Paradigms: \n",
    "* **Supervised Learning**: Models learn from labeled examples, where the correct outcomes or targets are known and provided. This is the most common type of ML (approx. 70% of applications).\n",
    "\n",
    "* **Unsupervised Learning**: Models find patterns and structure in data without labeled examples or correct answers. It discovers natural groupings or relationships on its own (e.g., customer segmentation).\n",
    "\n",
    "* **Reinforcement Learning**: An agent learns through interaction and feedback (trial and error), receiving rewards for good decisions and penalties for poor ones. It's powerful for sequential decision-making tasks like game playing.\n",
    "\n",
    "### 1.4 Features and Data Pre-processing\n",
    "* **Feature:** A specific piece of information or characteristic used as input for a model (e.g., square footage, number of bedrooms).\n",
    "\n",
    "* **Target (Dependent Variable / Label):** The value the model is trying to predict based on the features (e.g., the house price or 'spam'/'not spam').\n",
    "\n",
    "* **Feature Engineering:** The process of creating new, more informative features from existing raw data to improve model performance (e.g., transforming a raw date into 'is holiday').\n",
    "\n",
    "* **Feature Scaling / Normalization / Standardization:** Transforming numeric features to a similar scale to prevent features with larger ranges from dominating the learning process.\n",
    "\n",
    "* **Dimensionality:** The number of features in a dataset.\n",
    "\n",
    "### 1.5 Model Performance and Trade-offs\n",
    "* **Model Complexity:** How sophisticated a model is in capturing patterns, determined by the number of its parameters (e.g., number of layers in a neural network).\n",
    "\n",
    "* **Bias** is the inability of a machine learning method to accurately capture the true underlying relationship in the data.  Bias is the error introduced by approximating a real-world problem (which may be very complex) with a much simpler model. It measures how far the average prediction of your model is from the correct value.\n",
    "![bias](images/bias.jpg)\n",
    "\n",
    "* **Variance:** How much a model's predictions would change if it were trained on different subsets of the data. High variance indicates high sensitivity to the training data.\n",
    "\n",
    "* **Bias-Variance Trade-off:** \n",
    "\n",
    "*The tradeoff is that decreasing bias typically increases variance, and decreasing variance typically increases bias.*\n",
    "\n",
    "bias = incapability to capture the underlying relationship in the data.\n",
    "\n",
    "```capable (Low Bias) < (-1)------(0)------(1) > incapable (High Bias)```\n",
    "                \n",
    "variance = sensitivity to different data; difference in model performence for different data sets\n",
    "\n",
    "```consistent (Low Variance) < (-1)------(0)------(1) > very different (High Variance)```\n",
    "                \n",
    "\n",
    "The **ideal algorithm** must have **low bias** and **low variance**. This is achieved by finding the  sweet spotâ€”a model complexity that is flexible enough to capture the true relationship but simple enough to produce consistent predictions across different datasets.\n",
    "\n",
    "* **Noise:** Random variations or errors in data that don't represent true underlying patterns.\n",
    "\n",
    "* **Overfitting:** Occurs when a model learns the random noise and fluctuations in the training data instead of the true patterns, resulting in good training performance but poor generalization. The model has high variance.\n",
    "\n",
    "* **Underfitting:** Occurs when a model is too simple to capture the important patterns, resulting in poor performance on both training and test data. The model has *high bias*.\n",
    "\n",
    "* Low Complexity Model => High Bias, Low Variance (Underfitting)\n",
    "* High Complexity Mode => Low Bias, High Variance (Overfitting)\n",
    "\n",
    "### 1.6 Training anf Opyimization Techniques \n",
    "* **Validation:** Evaluating a model's performance on a held-out portion of the training data (the validation set) during the development process.\n",
    "\n",
    "* **Cross Validation:** Extends validation by repeatedly training and validating the model on different, multiple splits of the data for a more robust performance estimate.\n",
    "\n",
    "* **Batch:** A subset of training data processed together in a single step of training. The batch size is an important hyperparameter.\n",
    "\n",
    "* **Iteration:** A single pass through one batch of data, leading to an update of the model's parameters.\n",
    "\n",
    "* **Epoch:** A complete pass through the entire training data set. \n",
    "\n",
    "* **Parameter (Weight / Model Parameter):** A value that the model learns from the data during training (e.g., the slope and intercept in linear regression). Finding these is the goal of training.\n",
    "\n",
    "* **Hyperparameter:** A configuration setting set before training begins to control the learning process (e.g., learning rate, batch size, number of epochs).\n",
    "\n",
    "* **Learning Rate:** A crucial hyperparameter that determines how much the model adjusts its parameters in response to errors.\n",
    "\n",
    "* **Cost Function (Loss/Objective Function):** A measure of how wrong a model's predictions are compared to the true values. The goal of training is to minimize this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b2f28b",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Algorithms\n",
    "\n",
    "![ml](images/ml.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515e6ec",
   "metadata": {},
   "source": [
    "### 2.1. Supervised Learning; Regression vs Classification\n",
    "\n",
    "| Category       | Description                                                      | Example                                                                                        |\n",
    "| ---            | ---                                                              | ---                                                                                            |\n",
    "| Regression     |\tPredicting a continuous numeric target variable.                |\tPredicting the price of a house or a person's weight.                                        |\n",
    "| Classification |\tAssigning a discrete categorical label (class) to a data point. |\tClassifying an email as \"spam\" or \"not spam,\" or classifying an image as a \"cat\" or a \"dog.\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514da45",
   "metadata": {},
   "source": [
    "### 2.2 Regression:\n",
    "\n",
    "* **Linear Regression**:\n",
    "\n",
    "   * Goal: Determine a linear relationship between input and output variables. Predicts numerical values.\n",
    "\n",
    "   * Mechanics: Fits a straight line to the data by minimizing the sum of the squared distances between the data points and the regression line, thus minimizing prediction errors.\n",
    "![linear_reg](images/linear_regression.jpg)\n",
    "\n",
    "* **Logistic Regression:**\n",
    "\n",
    "   * Goal: The most basic classification algorithm. Logistic regression is fundamentally a classification algorithm, even though it's called \"regression.\" Its goal is to predict the probability of an event belonging to a particular class (e.g., probability of 'yes' or 'no', '1' or '0')\n",
    "\n",
    "   * Mechanics: Fits a sigmoid function (S-curve) to the data, which conveniently outputs the probability of a data point belonging to a certain class (e.g., the likelihood of an email being spam).\n",
    "\n",
    "   * $S(x) = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "![logistic_reg](images/logistic_reg.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6203b2e",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)\n",
    "* Goal: Used for both regression and classification. It is non-parametric (no equation or parameters are explicitly fitted).\n",
    "\n",
    "* Mechanics: For a new data point, the target is predicted to be the average (regression) or the majority class (classification) of its K closest neighbors in the training data.\n",
    "\n",
    "* Note: The value of K is a hyperparameter and must be tuned (e.g., by using cross-validation) to avoid overfitting or underfitting.\n",
    "\n",
    "![knn](images/knn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422d405",
   "metadata": {},
   "source": [
    "### Suport Vector Machine (SVM)\n",
    "* Goal: Primarily for classification, but can also be used for regression.\n",
    "\n",
    "* Mechanics: Draws a decision boundary (or hyperplane in higher dimensions) that separates the classes with the largest margin possible. The data points sitting on the edge of this margin are called support vectors.\n",
    "\n",
    "![svm1](images/svm1.jpg)\n",
    "![svm2](images/svm2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92139f",
   "metadata": {},
   "source": [
    "### 2.5 Naive Bayes Classifier\n",
    "* Goal: A classification algorithm often used for text-based tasks like spam filtering.\n",
    "\n",
    "* Mechanics: Uses Bayes' theorem to calculate the probability of a class based on the combined probabilities of all the words it contains. It is called \"naive\" because it falsely assumes that the probabilities of different words appearing are independent of each other.\n",
    "\n",
    "$P(A|B)=\\frac{P(B|A) * P(A)}{P(B)}$\n",
    "\n",
    "$P(spam| FMI, AI) = ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ca443",
   "metadata": {},
   "source": [
    "### 2.6 Decision Trees\n",
    "\n",
    "* Goal: Used for both classification and regression.\n",
    "\n",
    "* Mechanics: Creates a series of yes/no questions to partition the dataset. The goal is to create leaf nodes (the final outcomes) that are as \"pure\" as possible (meaning minimal misclassification).\n",
    "\n",
    "![tree](images/decision_tree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15601b67",
   "metadata": {},
   "source": [
    "### 2.6 Ensemble Methods: \n",
    "\n",
    "Combine many simple models (often decision trees) into a single, more powerful model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23791fac",
   "metadata": {},
   "source": [
    "### 2.7 Deep Learning \n",
    "\n",
    "Artificial Neural Networks (ANN) / Deep Learning:\n",
    "\n",
    "* Goal: The current reigning king of AI, used for complex classification and regression (e.g., image recognition).\n",
    "\n",
    "* Mechanics: Adds hidden layers of unknown variables between the input features and the output variable. These layers implicitly and automatically learn complex features from the raw data (e.g., identifying a \"horizontal line\" or a \"face\" in a picture without being explicitly programmed to do so)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a399d",
   "metadata": {},
   "source": [
    "### 2.8 Unsupervised Learning: K-Means\n",
    "Goal: To find unknown clusters or underlying groupings in unlabeled data. This is conceptually different from classification, where the groups are already known.\n",
    "\n",
    "**K-Means Clustering:**\n",
    "\n",
    "* Goal: The most famous clustering algorithm. K is the hyperparameter representing the number of clusters to find.\n",
    "\n",
    "* Mechanics: It iteratively selects random cluster centers, assigns every data point to the closest center, and then recalculates the center based on the newly assigned points, repeating until the centers stabilize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095a333",
   "metadata": {},
   "source": [
    "Pictures taken from: \n",
    "* https://www.youtube.com/watch?v=EuBBz3bI-aA&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=6 - Stats Quest\n",
    "* https://www.youtube.com/watch?v=E0Hmnixke2g&t=182s - Infinite Codes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
