{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e54b5ef",
   "metadata": {},
   "source": [
    "# Lab05: Games\n",
    "Overview of the lab: \n",
    "\n",
    "1. Games\n",
    "2. Minimax \n",
    "3. Alpha-beta pruning\n",
    "4. Additinal materials\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e980ec",
   "metadata": {},
   "source": [
    "## 1. Games\n",
    "* ***Perfect Information (Knowledge of Moves)***: Every player knows every move that has ever been made by all players up to the current point in the game. Think of it as no hidden history;\n",
    "\n",
    "* ***Complete Information (Knowledge of Rules/Payoffs)***: Every player knows the rules, possible strategies, and payoff structure for every player. Think of it as no hidden types/incentives; everyone knows what everyone else stands to gain or lose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c545e6d",
   "metadata": {},
   "source": [
    "|                          | deterministic  | chance           | \n",
    "|----                      | ----           |      ----        |\n",
    "| **perfect information**  | chess, go      | monopoly         |\n",
    "| **complete information** | batteships     | pocker, scrabble |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbca6a6",
   "metadata": {},
   "source": [
    "### Is it true that if the game has a perfect information it also has a compelete information?\n",
    "\n",
    "* Perfect Information:\t**All past moves.** Every player knows the entire history of actions taken in the game up to the current moment. (No hidden action).\tChess. Both players see every piece and every move made on the board.\n",
    "* Complete Information\t**All game rules/payoffs/types.** Every player knows the incentives (utility functions/payoffs) and strategies available to all other players. (No hidden rules/goals).\n",
    "\n",
    "NO! \n",
    "\n",
    "**The Game:** Imagine a sequential bargaining game where Player 1 makes a proposal, and Player 2 accepts or rejects it.\n",
    "\n",
    "* Perfect Information? Yes. Player 2 sees Player 1's proposal (the action). If Player 2 rejects, Player 1 sees the rejection. All moves are transparent.\n",
    "\n",
    "* Complete Information? Maybe Not. Player 1 might not know the exact minimum amount Player 2 is willing to accept (Player 2's payoff/type). Player 2's threshold is private, hidden information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859c861a",
   "metadata": {},
   "source": [
    "## 2. Minimax \n",
    "\n",
    "Its core principle is to **minimize the maximum possible loss** for the current player, assuming the opponent will always play optimally to maximize their own gain (and thus minimize your score).\n",
    "\n",
    "The name \"Minimax\" comes from the recursive alternation between two roles:\n",
    "1. MAX (Player1): Tries to Maximize the score.\n",
    "2. MIN (Player2): Tries to Minimize the score.\n",
    "\n",
    "### Game Tree \n",
    "Graph Representation: A game tree is a directed graph where:\n",
    "\n",
    "* **Nodes** represent a possible state of the game (e.g., a board configuration).\n",
    "* **Edges** represent a move from one game state to the next.\n",
    "\n",
    "### Minimax summarised:\n",
    "\n",
    "1. Minimax is a decision-making tool for two-player turn-taking games\n",
    "2. Minimax exploress a game tree by anticipating future moves. \n",
    "3. Minimax uses an Evaluation Function to assign scores to board states. \n",
    "4. Minimax strategically chooses the optimal path trough Recusrsive Exploration and Backtracking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41cdc9",
   "metadata": {},
   "source": [
    "### Evaluation functions\n",
    "\n",
    "Tic-Tac Toe:\n",
    "* Player(X) wins -> score: **+1**\n",
    "* Player(O) wins -> score: **-1**\n",
    "* Draw -> score: **0**\n",
    "\n",
    "![tictactoe_game_tree](images/tictactoe.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a91707",
   "metadata": {},
   "source": [
    "### Backtracking trough the Game Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239caa2b",
   "metadata": {},
   "source": [
    "![minimax_tree](images/minimax_tree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb287f",
   "metadata": {},
   "source": [
    "![minimax_q](images/minimax_q.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c2df0",
   "metadata": {},
   "source": [
    "![minimax_filled](images/minimax_filled.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33706c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Optimal Score for the starting MAX player is: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_terminal(node):\n",
    "    #implement logic to check if the game is over\n",
    "    return isinstance(node, int) # isinstance(node, int)\n",
    "\n",
    "def evaluate(node):\n",
    "    #if we are evaluating a board for example, this function should calculate a score\n",
    "    return node\n",
    "\n",
    "def get_children(node):\n",
    "    # computing next options from current node\n",
    "    return node\n",
    "\n",
    "def minimax(node, maximizingPlayer):\n",
    "    if is_terminal(node):\n",
    "        return evaluate(node)\n",
    "\n",
    "    if maximizingPlayer:\n",
    "        maxEval = -np.inf\n",
    "        for child in get_children(node):\n",
    "            eval = minimax(child, False)\n",
    "            maxEval = max(maxEval, eval)\n",
    "        return maxEval\n",
    "    else:\n",
    "        minEval = np.inf\n",
    "        for child in get_children(node):\n",
    "            eval = minimax(child, True)\n",
    "            minEval = min(minEval, eval)\n",
    "        return minEval\n",
    "\n",
    "game_tree = [\n",
    "    [\n",
    "        [-1, 3], \n",
    "        [5, 1]\n",
    "    ],\n",
    "    [\n",
    "        [-6, -4],\n",
    "        [0, 9]\n",
    "    ]\n",
    "]\n",
    "\n",
    "optimal_score = minimax(game_tree, True)\n",
    "print(f\"The Optimal Score for the starting MAX player is: {optimal_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9184f",
   "metadata": {},
   "source": [
    "### Properties of minimax\n",
    " \n",
    "**Complete?**  **Yes***, if the tree is finite\n",
    "\n",
    "----\n",
    "\n",
    "**Optimal?** - Yes, against an optimal opponent\n",
    "Conditions under which Minimax is optimal:\n",
    "\n",
    "### Conditions for Minimax Optimality\n",
    "\n",
    "The Minimax algorithm guarantees the optimal move *for the worst-case scenario* against a rational opponent, provided the following conditions hold true:\n",
    "\n",
    "* **Two-Player**\n",
    "   * Only two players are involved.\n",
    "   * The core $\\max/\\min$ structure breaks down with more players.\n",
    "* **Zero-Sum** \n",
    "   * The gain of one player is exactly the loss of the other.\n",
    "   * The $\\max$ player's goal (maximize my score) is exactly the inverse of the $\\min$ player's goal (minimize my opponent's score).\n",
    "* **Perfect Information**\n",
    "   * Both players know the entire state of the game (e.g., Chess, Checkers, Tic-Tac-Toe).\n",
    "   * the game involves hidden information (e.g., Poker), Minimax is no longer guaranteed to be optimal; other methods like Expected Minimax is needed.\n",
    "* **Deterministic** \n",
    "   * There is no element of chance (no dice, shuffled cards, etc.).\n",
    "   * If chance is involved, a variant called Expectimax is used, where the Minimax layers are interspersed with 'chance nodes' that calculate expected values.\n",
    "* **Complete Search**\n",
    "   * The algorithm must be able to search all the way to a terminal (game-ending) state.\n",
    "   * In real-world games like Chess, this is impossible. The algorithm stops at a fixed depth (the search horizon) and uses a heuristic (evaluation function) to estimate the value of the non-terminal nodes, making the result only heuristically optimal (an approximation).\n",
    "\n",
    "\n",
    "*Minimax is typically used in classical games like Chess, Checkers, and Tic-Tac-Toe.*\n",
    "\n",
    "The moment any of the above conditions are violated, or a practical limitation is introduced, Minimax ceases to be the \"optimal\" strategy:\n",
    "\n",
    "* **Against a Suboptimal Opponent:** Minimax will still win, but it might miss an opportunity to win faster or more decisively. If you know your opponent is weak, you could choose a \"trap\" move that Minimax rejects (because a perfect opponent would avoid the trap), but that an imperfect opponent is likely to fall for. \n",
    "\n",
    "* **Limited Search Depth:** As noted above, if the search is cut short by an arbitrary depth limit (which is necessary for complex games), the result is only as good as the heuristic evaluation function used at the leaves.\n",
    "\n",
    "----\n",
    "\n",
    "**Time complexity** - $O(b^m)$\n",
    "\n",
    "----\n",
    "**Space complexity** - $O(bm)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4d8d0",
   "metadata": {},
   "source": [
    "## Alpha-Beta pruning\n",
    "\n",
    "### Do we need to evaluate the whole game tree?\n",
    "\n",
    "![alpha_beta_1](images/alphabeta1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f9615",
   "metadata": {},
   "source": [
    "### NO\n",
    "![alphabeta2](images/alphabeta2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f00806",
   "metadata": {},
   "source": [
    "![alphabeta3](images/alphabeta3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260c142",
   "metadata": {},
   "source": [
    "Pruning depends on what order the moves are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d101256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: -1, minEval: -1, alpha: -inf, beta: -1\n",
      "eval: 3, minEval: -1, alpha: -inf, beta: -1\n",
      "eval: -1, minEval: -1, alpha: -1, beta: inf\n",
      "eval: 5, minEval: 5, alpha: -1, beta: 5\n",
      "eval: 1, minEval: 1, alpha: -1, beta: 1\n",
      "eval: 1, minEval: 1, alpha: 1, beta: inf\n",
      "eval: 1, minEval: 1, alpha: -inf, beta: 1\n",
      "eval: -6, minEval: -6, alpha: -inf, beta: -6\n",
      "eval: -4, minEval: -6, alpha: -inf, beta: -6\n",
      "eval: -6, minEval: -6, alpha: -6, beta: 1\n",
      "eval: 0, minEval: 0, alpha: -6, beta: 0\n",
      "eval: 9, minEval: 0, alpha: -6, beta: 0\n",
      "eval: 0, minEval: 0, alpha: 0, beta: 1\n",
      "eval: 0, minEval: 0, alpha: -inf, beta: 0\n",
      "The Optimal Score for the starting MAX player is: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_terminal(node):\n",
    "    #implement logic to check if the game is over\n",
    "    return isinstance(node, int) # isinstance(node, int)\n",
    "\n",
    "def evaluate(node):\n",
    "    #if we are evaluating a board for example, this function should calculate a score\n",
    "    return node\n",
    "\n",
    "def get_children(node):\n",
    "    # computing next options from current node\n",
    "    return node\n",
    "\n",
    "def minimax(node, alpha, beta, maximizingPlayer):\n",
    "    if is_terminal(node):\n",
    "        return evaluate(node)\n",
    "\n",
    "    if maximizingPlayer:\n",
    "        maxEval = -np.inf\n",
    "        for child in get_children(node):\n",
    "            eval = minimax(child, alpha, beta, False)\n",
    "            maxEval = max(maxEval, eval)\n",
    "            alpha = max(alpha, eval)\n",
    "            print(f\"eval: {eval}, minEval: {maxEval}, alpha: {alpha}, beta: {beta}\")\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return maxEval\n",
    "    else:\n",
    "        minEval = np.inf\n",
    "        for child in get_children(node):\n",
    "            eval = minimax(child, alpha, beta, True)\n",
    "            minEval = min(minEval, eval)\n",
    "            beta = min(beta, eval)\n",
    "            print(f\"eval: {eval}, minEval: {minEval}, alpha: {alpha}, beta: {beta}\")\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "\n",
    "        return minEval\n",
    "\n",
    "game_tree = [\n",
    "    [\n",
    "        [-1, 3], \n",
    "        [5, 1]\n",
    "    ],\n",
    "    [\n",
    "        [-6, -4],\n",
    "        [0, 9]\n",
    "    ]\n",
    "]\n",
    "\n",
    "optimal_score = minimax(game_tree, -np.inf, np.inf,  False)\n",
    "print(f\"The Optimal Score for the starting MAX player is: {optimal_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e915b6",
   "metadata": {},
   "source": [
    "![ab1](images/albt1.jpg)\n",
    "![ab2](images/albt2.jpg)\n",
    "![ab3](images/albt3.jpg)\n",
    "![ab4](images/albt4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43936e",
   "metadata": {},
   "source": [
    "$\\alpha$ - the best value that MAX can garantee at the current level and the levels above (upper levels)\n",
    "\n",
    "$\\beta$ - the best value that MIN can garantee at the current level and the levels above\\\n",
    "\n",
    "**Recuirement for pruning**: $\\beta \\leq \\alpha$ \n",
    " * Min had a better option available earlier in the tree\n",
    "\n",
    "### Properties of Alpha-Beta Pruning\n",
    "* Pruning does not affect final result.\n",
    "* Good move ordering improves effectiveness of pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84751a6",
   "metadata": {},
   "source": [
    "* cutoff test = e.g., depth limit (perhaps add quiescence search)\n",
    "\n",
    "* evaluation function = estimated desirability of position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad63fb",
   "metadata": {},
   "source": [
    "## 4. Additinal Materials \n",
    "1. Tic tac toe - [here](https://www.neverstopbuilding.com/blog/minimax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
